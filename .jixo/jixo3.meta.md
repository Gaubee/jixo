[.jixo/coder.jixo.md](@Inject)

---

### 历史故事

**5月20号**
我在做基于单个巨大的提示词文件的AI应用了。这个应用叫做JIXO。
现在我想将我的AI应用升级到基于 mastra.ai 的这个框架下的应用。

这是我之前的“系统提示词”：

[packages/cli/prompts/system.md](@File)

还有“用户提示词的模板文件”：

[packages/cli/prompts/user.md](@File)

以及生成“系统提示词”和“用户提示词模板”的“元提示词”，这是更高维度的一个信息源头，可能很重要：

[.jixo/jixo-gen-system-prompt.md](@File)

**6月05号**
然后我跟你讲一下为什么我要把我的JIXO应用迁移到 mastra.ai 这个框架下。

核心原因是，我的在编写提示词的过程中，一直在对抗AI的幻觉问题，同时也慢慢梳理出了双层循环的架构来让AI持久地一直运行下去。但是由于幻觉，导致AI没法很好的履行我提示词中提出的要求。

因此我提出了让提示词更进一步地严格，甚至已经严格到“代码级别”了，这其实已经脱离传统意义上“语义化”的提示词了，而更倾向于代码级别，也就是这时候我开始意识到，一个工业级别的AI应用，是需要基于状态机的架构来管控AI的每一个工作节点的。
也因此我调查到最前沿的 LangGraph、LlamaIndex 都是这个想法的产物。
所以我选择了一个比较成熟的 mastra.ai 这个框架，帮助我快速实现JIXO这个应用。

---

以下是mastra的官方文档介绍：

[.jixo/mastra-llms-full.md](@FILE)

---

我已经完成了 JIXO-V3 原型的开发，基本走通了JIXO的基础工作流了。以下是JIXO-v3的最新源代码：

[`packages/core/src/**/*.ts`](@File)

我自己已经尝试搭建出来了webui这个项目，并且也基本走通了基本的对话能力，以下是主要源代码：

[`packages/webui/{app,components,hooks,lib}/**/*.{ts,tsx,css}`](@File)

目前我只是搭建了这个WebUI，但主要的精力不在这里，今天我搭建这个webui的目的只是为了验证core部分的设计符合预期，并且探明一些问题，方面我做更好的设计。

我已经成功和AI完成了cli项目的初步搭建

[`packages/cli/src/**/*.ts`](@File)

它采用C/S架构，将core作为一个独立的进程来启动，然后cli只是通过http接口来调用core。
就就跟webui一样，未来也许还能跟webui共享一些逻辑呢。

未来我们可以把core作为一个守护进程来在后台长时间启动，cli只是一个控制它的终端入口。

这样一来的话，我们得在cli命令中增加一个 daemon 子命令。可以用来管理和维护core进程。
比如可以控制它的启动、停止、重启、查看状态、查看日志等等。

不过现在先不急着实现守护进程。今天补充了workspace这个概念，将`.jixo`文件夹所在的地方作为一个worksapce，这里会有一个独立的jixo-core进程来管理这个工作空间。

每个工作空间都有独立的配置文件，里面存放着这个工作空间相关的信息。

未来还会有一个全局空间，用来注册管理所有的工作空间，有一些配置还可以和全局空间一起使用。

---

接下来，JIXO 将开始逐步产品化，达到一个稳定的产品，需要做到这几点：

1. 构建 `jixo-cli` 工具，方便开发者使用cli工具快速完成调用JIXO的能力。
1. 构建 `jixo-webui` 界面，使得开发者和普通用户都可以在网页上调用JIXO的能力、观察JIXO的工作情况。
1. `gen-workflow-tool`“工作流生成工具”，JIXO 的内核将支持动态工作流的构建：
   1. 比如可以用一个json来描述一个工作流（类似JIT机制）。
   1. （次要）可以将json工作流变编译成ts代码（类似AOT机制），这样一来，开发者可以在其中做更加复杂的开发，提升这个工作流的能力边界。
1. 自我进化：
   1. 实现`fluid-intelligence`（流体智能），培养底层思维方式和本能，从而做到适应环境需求的自我进化能力。
      1. 具体到AI编程领域，就是动态生成代码：代码基于workflow这个功能。遇到一个问题时：在思考的时候，从入口开始，逐渐基于workflow的流程来进行思考，甚至并行地进行多方位的思考，然后汇总收敛出一份针对问题的 distillation-workflow（下文简称 dflow） 。接下来解决问题可以直接使用这个dflow来进行工作。同时这个dflow融合到 fluid-intelligence 中去，成为 fluid-intelligence 的一部分。
      1. 上文提到的是“加法”，流体智能更重要的是“减法”，减法不是一味地删减，而是“融合”。但是跟代码说“融合”，并不现实，这里的客观工作原理是基因仿生，就是找到相似的 dflow，让它们同时进行相同的工作，然后通过评估（AI评估或者人工评估或者环境反馈式的评估）最终确定出更优秀的dflow。
   1. 实现`Solid-intelligence`（固体智能），本质就是学习技能，这里底层用的是RAG数据库，存储知识、同时也要生成固定的workflow来存储技能。
      1. 实现`research-workflow`（研究工作流），通过提供一些资料（链接、文件等），它可以生成适用于AI的知识库资料，存储到本地RAG数据库中。
      1. 实现`evolve-workflow`（进化工作流），基于数据库里的内容（包括知识、和工作日志），“进化工作流”将尝试使用“工作流生成工具”生成工作流，然后执行它，对工作流的效果做评估，从而不停地调整工作流、重构工作流，直到它稳定、符合外部审查的结果。
1. 构建 `jixo-bot` 应用，它是一个24小时运行的超级AI应用，具有感知能力，并基于感知的去触发工作流、调控工作流。
   1. 比如最常见的感知就是多模态输入（文字、语音、图片、视频、摄像头、等）
   1. 还有比如如果运行在个人PC上，那么还能监听文件夹变更、查看用户的桌面、用户的键盘鼠标输入等等。
   1. 它还能提供一个浏览器，从而实施操作浏览器，用户可以在这个浏览器上和它一同协作操作网页，完整复杂的网页操作。
   1. 也能接入或者控制一些外部信号，比如USB设备、蓝牙设备等等。

以上是一个相对宏观的JIXO的愿景。
以下是近期的一些关于JIXO的工作内容的笔记：

1. daemon并不急着实现，需要我们完成 workspaceManager 和 rootManager（基于操作系统的用户空间）之后，基于rootManager来实现。
   1. 这里一个workspaceManager可以管理多个logManager
   1. 未来logManager需要升级成jobManager，这里还需要引入更多元的功能，否则目前来说，它就是一个logManager，理论上还应该有 workflowManager、agentManager、toolManager 等等更多的manager，才能组合出一个真正意义上的jobManager。目前workflow、agent、tool这些都是固定的，还不够有灵活性。所以目前来说，用logManager这个名字比较恰当。
   1. 每一个workspaceManager会被注册到rootManager中，rootManager会管理所有的workspaceManager。daemon就基于rootManager来实现的。
   1. rootManager还会有一些“根配置”，可以用来和workspaceManager共享。
   1. 综合来说，daemon不急着实现，需要等到条件成熟了再说。
1. cli项目和webui项目现在不是T1的任务，core才是T1，需要等到core中的一些功能和设计稳定下来了，才开始下放到cli、webui中来对外提供这些功能。

1. plan + execute + review 这三者的关系，是我尝试在模拟人类的一种“通用”思维。我是想将这三者打包成一个“AI神经元”。
   1. plan 用来向前看、生成计划、生成验收标准。它需要充分调用“思考”，将目标进行分解。
      1. 这里的思考，包括模型本身的深度思考能力，也包含未来JIXO内置的“流式智能”
   1. execute 是用来践行计划内容，它需要调用技能文档、工具，来完成任务。
      1. 这里的技能文档主要是来自“固体智能”，主要包括读取RAG以及执行技能工作流
      1. 这里的工具，最开始是人类提供给AI的工具，后续JIXO逐步能够自己创造工具、测试工具、验证工具、交付工具、迭代工具。
   1. review 基于验收标准对execute的产出进行验收，它的工作方式其实跟execute很像，都是在调用工具来完成任务，不同的是execute是完成对外的目标，review是完成对内的目标。
      1. 这里的对内完成目标，具体点就是说，它需要生成一些指标数据，来评估plan和execute这次的配合怎么样。基于这些评估数据，自然会有其它的工作流来接受处理，从而对“流式智能”和“固体智能”进行升级。
